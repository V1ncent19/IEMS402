\documentclass[11pt,a4paper]{ctexart}
%以下为所使用的宏包
\usepackage{ulem}%下划线
\usepackage{amsmath,amsfonts,amssymb,amsthm,amsbsy}%数学符号
\usepackage{graphicx}%插入图片
\usepackage{booktabs}%三线表
%\usepackage{indentfirst}%首行缩进
\usepackage{tikz}%作图
\usepackage{appendix}%附录
\usepackage{array}%多行公式/数组
\usepackage{makecell}%表格缩并
\usepackage{siunitx}%SI单位--\SI{number}{unit}
\usepackage{mathrsfs}%数学字体
\usepackage{enumitem}%列表间距
\usepackage{multirow}%列表横向合并单元格
\usepackage[colorlinks,linkcolor=red,anchorcolor=blue,citecolor=green]{hyperref}%超链接引用
\usepackage{float}%图片、表格位置排版
\usepackage{pict2e,keyval,fp,diagbox}%带有斜线的表格
\usepackage{fancyvrb,listings}%设置代码插入环境
\usepackage{minted}%代码环境设置
\usepackage{fontspec}%字体设置
\usepackage{color,xcolor}%颜色设置
\usepackage{titlesec} %自定义标题格式
\usepackage{tabularx}%列表扩展
\usepackage{authblk}%titlepage作者信息
\usepackage{nicematrix}%更好的矩阵标定
\usepackage{fbox}%更多浮动体盒子



%以下是页边距设置
\usepackage[left=0.5in,right=0.5in,top=0.81in,bottom=0.8in]{geometry}

%以下是段行设置
\linespread{1.4}%行距
\setlength{\parskip}{0.1\baselineskip}%段距
\setlength{\parindent}{2em}%缩进


%其他设置
\numberwithin{equation}{section}%公式按照章节编号
\newenvironment{point}{\raggedright$\blacktriangleright$}{}
\newenvironment{algorithm}[1]{\vspace{12pt} \hrule\hrule \vspace{3pt} \noindent\textbf{\color[HTML]{E63F00}Algorithm } \,\textit{#1} \vspace{3pt} \hrule\vspace{6pt}}{\vspace{6pt}\hrule\hrule \vspace{12pt}} % 算法伪代码格式环境


%代码环境\lst设置
\definecolor{CodeBlue}{HTML}{268BD2}
\definecolor{CodeBlue2}{HTML}{0000CD}
\definecolor{CodeGreen}{HTML}{2AA1A2}
\definecolor{CodeRed}{HTML}{CB4B16}
\definecolor{CodeYellow}{HTML}{B58900}
\definecolor{CodePurPle}{HTML}{D33682}
\definecolor{CodeGreen2}{HTML}{859900}
\lstset{
    basicstyle=\tt,%字体设置
    numbers=left, %设置行号位置
    numberstyle=\tiny\color{black}, %设置行号大小
    keywordstyle=\color{black}, %设置关键字颜色
    stringstyle=\color{CodeRed}, %设置字符串颜色
    commentstyle=\color{CodeGreen}, %设置注释颜色
    frame=single, %设置边框格式
    escapeinside=`, %逃逸字符(1左面的键)，用于显示中文
    %breaklines, %自动折行
    extendedchars=false, %解决代码跨页时，章节标题，页眉等汉字不显示的问题
    xleftmargin=2em,xrightmargin=2em, aboveskip=1em, %设置边距
    tabsize=4, %设置tab空格数
    showspaces=false, %不显示空格
    emph={TRUE,FALSE,NULL,NAN,NA,<-,},emphstyle=\color{CodeBlue2}, %其他高亮}
}


%节标题格式设置
\titleformat{\section}[block]{\large\bfseries}{Exercise \arabic{section}}{1em}{}[]
\titleformat{\subsection}[block]{}{    \arabic{section}.(\alph{subsection})}{0.3em}{}[]
\titleformat{\subsubsection}[block]{\normalsize}{    \arabic{section}.(\alph{subsection}).(\roman{subsubsection})}{0.3em}{}[]
% \titleformat{\paragraph}[block]{\small\bfseries}{[\arabic{paragraph}]}{1em}{}[]


% \titleformat{\sectioncommand}[shape]{format}{title-label}{sep}{before-title}[after-title]



% 中文字号
% 初号42pt, 小初36pt, 一号26pt, 小一24pt, 二号22pt, 小二18pt, 三号16pt, 小三15pt, 四号14pt, 小四12pt, 五号10.5pt, 小五9pt


\begin{document}

\begin{center}\thispagestyle{plain}

{\LARGE\textbf{IEMS 402 Statistical Learning - 2025 Winter}}

{\Large\textbf{HW4}}

Tuorui Peng\footnote{TuoruiPeng2028@u.northwestern.edu}
\end{center}

\thispagestyle{myheadings}\markright{Compiled using \LaTeX}
\pagestyle{myheadings}\markright{Tuorui Peng}




\section{Estimating the Derivatives via Kernel Smoothing }

\begin{itemize}[topsep=2pt,itemsep=0pt]
    \item Bias term:
    \begin{align*}
        \left\vert d_n(x) - p'(x) \right\vert =& \left\vert \int_{-1}^1 \dfrac{ 1 }{ h^2 } K\left( \dfrac{ X_i-x }{ h } \right) p(x) \,\mathrm{d}x  - p'(x) \right\vert \\
        =&\dfrac{ 1 }{ h } \left\vert \int K(\left\Vert v \right\Vert )\big( p(x+hv) - v p'(x)\big) \,\mathrm{d}v  \right\vert \\
        =&\dfrac{ 1 }{ h } \left\vert \int K(\left\Vert v \right\Vert )\big( p(x+hv) - vp'_{x,\beta }(x+hv) +vp'_{x,\beta }(x+hv) -v  p'(x)\big) \,\mathrm{d}v  \right\vert \\
        \leq & \dfrac{ 1 }{ h } \int K(\left\Vert v \right\Vert )\left\vert p(x+hv) - vp'_{x,\beta }(x+hv) \right\vert \,\mathrm{d}v + \dfrac{ 1 }{ h } \int K(\left\Vert v \right\Vert )\left\vert vp'_{x,\beta }(x+hv) -v  p'(x)\right\vert \,\mathrm{d}v\\
        \lesssim & Lh^{\beta-1} \int K(\left\Vert v \right\Vert )\left\vert v \right\vert \,\mathrm{d}v 
    \end{align*}
    in which the last inequality is because $ p(\, \cdot \, ) - p_{x,\beta }(\, \cdot \, ) $ is still a $ \beta $-H\"older function.
    \begin{align*}
         var(d_n(x)) \leq & \dfrac{ 1 }{ nh^4 } \int K^2(\dfrac{ X_i-x }{ h  } ) p(x) \,\mathrm{d}x \\
         =& \dfrac{ 1 }{ nh^3 } \int K^2(v) p(x+hv) \,\mathrm{d}v \\
         \lesssim & \dfrac{ 1 }{ nh^3 } \sup_{x\in [-1,1]} p(x) \int K^2(v) \,\mathrm{d}v
    \end{align*}
    where the last inequality is because only the first order term of $ p(\, \cdot \, ) $ gives non-zero kernel integration.
    
\end{itemize}

Put together, we have
\begin{align*}
    \mathrm{ MSE } \lesssim h^{2(\beta -1 )} + \dfrac{ 1 }{ nh^3 } 
\end{align*}
Optimal $ h_n $ is at $ h_n \asymp n^{-\frac{ 1 }{ 2\beta + 1 }} $, and the optimal MSE is $ n^{-\frac{ 2(\beta-1) }{ 2\beta + 1 }} $.


    

\section{An average treatment effect estimator}

\subsection{}
In completely randomized experiment, we can see that 
\begin{align*}
    \mathbb{E}\left[ Y_i(a)1\{A_i=a\} \right] =& \dfrac{ 1 }{ 2 }\mathbb{E}\left[ Y_i(a)1\{A_i=a\} |A_i = 0 \right]    + \dfrac{ 1 }{ 2 }\mathbb{E}\left[ Y_i(a)1\{A_i=a\} |A_i = 1 \right]\\
    =& \begin{cases}
        \dfrac{ 1 }{ 2 }\mathbb{E}\left[ Y_i(0) |A_i = 0 \right]    ,&\text{if } a = 0\\
        \dfrac{ 1 }{ 2 }\mathbb{E}\left[ Y_i(1) |A_i = 1 \right]    ,&\text{if } a = 1
    \end{cases}\\
    =& \dfrac{ 1 }{ 2 } \mathbb{E}\left[ Y_i(a) \right] = \dfrac{ 1 }{ 2 }\mathbb{E}\left[ Y(a) \right]
\end{align*}

and we have ATE being
\begin{align*}
    \tau = \mathbb{E}\left[ Y(1) \right] - \mathbb{E}\left[ Y(0) \right] = 2\mathbb{E}\left[ Y(1)1\{A=1\} \right] - 2\mathbb{E}\left[ Y(0)1\{A=0\} \right].
\end{align*}

\subsection{}
Note that we can write $ \hat{\tau}_n $ as 
\begin{align*}
    \hat{\tau}_n =& \dfrac{ 1 }{ n }\big[2 Y_i(1)1\{A_i=1\} - 2 Y_i(0)1\{A_i=0\}\big]\\
    \mathbb{E}\left[ 2 Y_i(1)1\{A_i=1\} - 2 Y_i(0)1\{A_i=0\} \right] = & \tau\\
    var(2 Y_i(1)1\{A_i=1\} - 2 Y_i(0)1\{A_i=0\}) =& var(\mathbb{E}\left[ 2 Y_i(1)1\{A_i=1\} - 2 Y_i(0)1\{A_i=0\} |A \right]) \\ &+ \mathbb{E}\left[ var(2 Y_i(1)1\{A_i=1\} - 2 Y_i(0)1\{A_i=0\} |A) \right]\\
    =& (\mathbb{E}\left[ Y(1) \right] +\mathbb{E}\left[ Y(0) \right] ) ^2 + 2 \big(var(Y(1)) + var(Y(0))\big)
\end{align*}

By CLT
\begin{align*}
    \sqrt{n}(\hat{\tau}_n-\tau) \xrightarrow[]{\mathrm{d}} N(0, (\mu _1 + \mu _0)^2 + 2(\sigma _1^2 + \sigma _0^2)),\quad \mu _a = \mathbb{E}\left[ Y(a) \right],\sigma _a^2 = var(Y(a))
\end{align*}



\subsection{}







Note that for completely randomized experiment, we have $ \left\vert S_1 \right\vert = n- \left\vert S_0 \right\vert \sim \mathrm{ Binomial }(n, \dfrac{ 1 }{ 2 }) $. Thus we get (take $ a=1 $ example)
\begin{align*}
    \begin{cases}
        \sqrt{n}(1-2\left\vert S_1 \right\vert /n ) \xrightarrow[]{\mathrm{d}} N(0, 1)\\
        2\left\vert S_1 \right\vert /n \xrightarrow[]{\mathrm{p}} 1
    \end{cases} \mathop{  \Rightarrow  }\limits^{\mathrm{ Slutsky }} \sqrt{n}(\dfrac{ n  }{ 2\left\vert S_1\right\vert }    -1 ) \xrightarrow[]{\mathrm{d}} N(0, 1)  
\end{align*}
and similarly for $ a=0 $ we have $ \sqrt{n}(\dfrac{ n  }{ 2\left\vert S_0\right\vert }    -1 ) \xrightarrow[]{\mathrm{d}} N(0, 1)  $.




\subsection{}


We have
\begin{align*}
    \sqrt{n}(\hat{\tau}_n^\mathrm{ norm } -\tau) = &\dfrac{ \sqrt{n} }{ \sqrt{\left\vert S_1 \right\vert } }  \sqrt{\left\vert S_1 \right\vert } \big( \dfrac{ 1 }{ \left\vert S_1 \right\vert  }\sum_i (Y_i(1) - \mathbb{E}\left[ Y(1) \right] )1\{A_i=1\}    \big) \\ & + \dfrac{ \sqrt{n} }{ \sqrt{\left\vert S_0 \right\vert } }  \sqrt{\left\vert S_0 \right\vert } \big( \dfrac{ 1 }{ \left\vert S_0 \right\vert  }\sum_i (Y_i(0) - \mathbb{E}\left[ Y(0) \right] )1\{A_i=0\}    \big)
\end{align*}

For now we treat $ A $ as given, and we have
\begin{align*}
    \sqrt{n}(\hat{\tau}_n^\mathrm{ norm } -\tau)\big| A \xrightarrow[]{\mathrm{d}} \dfrac{ \sqrt{n} }{ \sqrt{\left\vert S_1 \right\vert } } N(0, \sigma _1^2) + \dfrac{ \sqrt{n} }{ \sqrt{\left\vert S_0 \right\vert } } N(0, \sigma _0^2)
\end{align*}

On the other hand we notice that we already have
\begin{align*}
    \dfrac{ \sqrt{n} }{ \sqrt{\left\vert S_1 \right\vert } } \xrightarrow[]{\mathrm{p}} \sqrt{2},\quad \dfrac{ \sqrt{n} }{ \sqrt{\left\vert S_0 \right\vert } } \xrightarrow[]{\mathrm{p}} \sqrt{2},\quad cov\left( \dfrac{ n }{ \left\vert S_1 \right\vert }, \dfrac{ n }{ \left\vert S_0 \right\vert } \right) = -1
\end{align*}

Thus by Slutsky's theorem, we have
\begin{align*}
    \sqrt{n}(\hat{\tau}_n^\mathrm{ norm } -\tau) \xrightarrow[]{\mathrm{d}}N(0, \sigma ^2_\mathrm{ norm }) 
\end{align*}
where
\begin{align*}
    \sigma ^2_\mathrm{ norm } = 2\sigma _1^2 + 2\sigma _0^2 
\end{align*}







% Similar to (b), we can see that 
% \begin{align*}
%     \sqrt{n}(\hat{\tau}_n^\mathrm{ norm }  -\tau ) \big| S_a \xrightarrow[]{\mathrm{d}} N(0, var(\hat{\tau}_n^\mathrm{ norm }  )),\quad var(\hat{\tau}_n^\mathrm{ norm }  ) = \dfrac{ \sigma _1^2 }{ \left\vert S_1 \right\vert  } + \dfrac{ \sigma _0^2 }{ \left\vert S_0 \right\vert  } ,\quad \left\vert S_1 \right\vert + \left\vert S_0 \right\vert =n
% \end{align*}

% thus we have
% \begin{align*}
%     \sqrt{n}(\hat{\tau}_n^\mathrm{ norm }  -\tau ) \big| S_a \xrightarrow[]{\mathrm{d}} \sqrt{\dfrac{ \sigma _1^2 }{ \left\vert S_1 \right\vert  } + \dfrac{ \sigma _0^2 }{ \left\vert S_0 \right\vert  }} N(0,1)
% \end{align*}
% while we see that $ \dfrac{ 1 }{ \left\vert S_a  \right\vert  } \xrightarrow[]{\mathrm{p}}   $






\subsection{}

It seems that based on our results up to now, the conlusion would be that: 
\begin{align*}
    \sqrt{n} (\hat{\tau}_n-\tau)&\xrightarrow[]{\mathrm{d}} N(0, \sigma ^2),\quad \sigma ^2 = (\tau_1+\tau_0)^2 + 2(\sigma _1^2 + \sigma _0^2)\\
    \sqrt{n} (\hat{\tau}_n^\mathrm{ norm }-\tau)&\xrightarrow[]{\mathrm{d}} N(0, \sigma ^2_\mathrm{ norm }),\quad \sigma ^2_\mathrm{ norm } = 2(\sigma _1^2 + \sigma _0^2)
\end{align*}
so we have $ \sigma ^2>\sigma ^2_\mathrm{ norm  }  $ as long as $ \tau_1+\tau_0 > 0 $.





\section{A weighted average treatment effect estimator}
\subsection{}

With the covariate $ X $ involved, we have
\begin{align*}
    \tau =& \mathbb{E}\left[ Y(1) \right]  - \mathbb{E}\left[ Y(0) \right]\\
    =& \mathbb{E}\left[ \mathbb{E}\left[ Y(1)\big(1\{A=1\} + 1\{A=0\}\big) \big| X=x \right]  \right] - \mathbb{E}\left[ \mathbb{E}\left[ Y(0)\big(1\{A=1\} + 1\{A=0\}\big) \big| X=x \right]  \right]
\end{align*}
now note that since $ (Y(1),Y(0)) \perp A |X $, we have
\begin{align*}
    \mathbb{E}\left[ Y(A)1\{A=1\}|X=x \right] =& Y(1)e(x) \\
    \mathbb{E}\left[ Y(A)1\{A=0\}|X=x \right] =& Y(0)(1-e(x))
\end{align*}
substitute this back to the above equation, we have
\begin{align*}
    \tau =& \mathbb{E}\left[ \dfrac{ Y(A)1\{A=1\} }{ e(x) }\big(1\{A=1\} + 1\{A=0\}\big) - \dfrac{ Y(A)1\{A=0\} }{ 1-e(x) }\big(1\{A=1\} + 1\{A=0\}\big) \Big| X=x\right]\\
    =& \mathbb{E}\left[ \dfrac{ Y(A)1\{A=1\} }{ e(x) } - \dfrac{ Y(A)1\{A=0\} }{ 1-e(x) } \Big| X=x\right]\\
    =& \mathbb{E}\left[ \dfrac{ Y(A)1\{A=1\} }{ e(X) }  \right] - \mathbb{E}\left[ \dfrac{ Y(A)1\{A=0\} }{ 1-e(X) }  \right] 
\end{align*}

\subsection{}



\subsection{}


\section{Logistic regression}








\end{document}